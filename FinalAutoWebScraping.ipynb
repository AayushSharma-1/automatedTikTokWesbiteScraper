{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96986965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "path = input(\"Enter Path of csv\")\n",
    "df = pd.read_csv(path)\n",
    "user_links = df['user_links'].to_list()\n",
    "video_links = df['links'].to_list()\n",
    "\n",
    "\n",
    "followers = []\n",
    "following = []\n",
    "\n",
    "no_of_links = int(input(\"Enter the number of links to scrape --------> it should be less than the size of csv file\"))\n",
    "\n",
    "print(\"<--------------------Scraping------------------------->\")\n",
    "\n",
    "for i in user_links[:no_of_links]:\n",
    "    response = requests.get(i)\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        if len(soup.find_all('strong', attrs = {'data-e2e':\"followers-count\"}))!= 0:\n",
    "            followers.append(soup.find_all('strong', attrs = {'data-e2e':\"followers-count\"}))\n",
    "        else:\n",
    "            followers.append('<strong>nil</strong>')\n",
    "        if len(soup.find_all('strong', attrs = {'data-e2e':\"following-count\"}))!= 0:\n",
    "            following.append(soup.find_all('strong', attrs = {'data-e2e':\"following-count\"}))\n",
    "        else:\n",
    "            following.append('<strong>nil</strong>')\n",
    "            \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        followers.append('<strong>no-response</strong>')\n",
    "        following.append('<strong>no-response</strong>')\n",
    "        \n",
    "print(\"<----------------------Done-------------------->\")\n",
    "print(\"<---------------Creating DataFrame------------->\")\n",
    "        \n",
    "followers_count = []\n",
    "following_count = []\n",
    "for item1,item2 in zip(followers, following):\n",
    "    soup1 = BeautifulSoup(str(item1), 'html.parser')\n",
    "    soup2 = BeautifulSoup(str(item2), 'html.parser')\n",
    "    \n",
    "    strong_tags1 = soup1.find_all('strong')\n",
    "    strong_tags2 = soup2.find_all('strong')\n",
    "    \n",
    "    for item1, item2 in zip(strong_tags1, strong_tags2):\n",
    "        followers_count.append(item1.get_text())\n",
    "        following_count.append(item2.get_text())\n",
    "        \n",
    "data = { 'profile_links': user_links[:no_of_links],\n",
    "         'video_links' :  video_links[:no_of_links],\n",
    "         'followers' : followers_count,\n",
    "         'following' : following_count   \n",
    "}\n",
    "df2 = pd.DataFrame(data)\n",
    "df2\n",
    "df.to_csv(\"name.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
